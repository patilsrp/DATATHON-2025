{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\Smruti Deshpande\\\\Desktop\\\\Projects\\\\Datathon_kj\\\\elearning_churn_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Smruti Deshpande\\AppData\\Local\\Temp\\ipykernel_15904\\3177323329.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[categorical_cols] = df[categorical_cols].apply(lambda x: x.fillna(method='ffill'))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Handle Missing Values\n",
    "# For numerical columns, we fill with median or mean based on the nature of the column\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_cols] = df[numerical_cols].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# For categorical columns, we fill missing values using forward fill or backward fill\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "df[categorical_cols] = df[categorical_cols].apply(lambda x: x.fillna(method='ffill'))\n",
    "\n",
    "# Handle Duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Feature Engineering\n",
    "# Engagement Score Calculation\n",
    "df['Engagement Score'] = df['Login Frequency (per month)'] * df['Time Spent per Session (mins)']\n",
    "\n",
    "# Encode Categorical Features\n",
    "encoder = LabelEncoder()\n",
    "df['Subscription Plan'] = encoder.fit_transform(df['Subscription Plan'])\n",
    "df['Feedback Sentiment'] = encoder.fit_transform(df['Feedback Sentiment'])\n",
    "df['Support Ticket Sentiment'] = encoder.fit_transform(df['Support Ticket Sentiment'])\n",
    "df['Course Reminder Response'] = encoder.fit_transform(df['Course Reminder Response'])\n",
    "df['Gamified Progress Engagement'] = encoder.fit_transform(df['Gamified Progress Engagement'])\n",
    "\n",
    "# Convert Date columns to datetime\n",
    "df['Enrollment Date'] = pd.to_datetime(df['Enrollment Date'], format='%d-%m-%Y')\n",
    "df['Last Active Date'] = pd.to_datetime(df['Last Active Date'], format='%d-%m-%Y')\n",
    "\n",
    "# Calculate the days since last active\n",
    "df['Days Since Last Active'] = (pd.to_datetime('today') - df['Last Active Date']).dt.days\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical\n",
    "_cols])\n",
    "\n",
    "# Separate Independent Variables and Target Variable\n",
    "X = df.drop(['churn'], axis=1)  # Independent features\n",
    "y = df['churn']  # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.6.0+cu118)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers[torch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (2.6.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (0.28.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0) (0.5.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate>=0.26.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smruti deshpande\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"accelerate>=0.26.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1000, 23)\n",
      "  User ID Enrollment Date  Subscription Plan  Course Completion Rate  \\\n",
      "0   U0001      2022-04-13                  0               -0.448101   \n",
      "1   U0002      2023-03-12                  0               -0.373640   \n",
      "2   U0003      2022-09-28                  2                0.235746   \n",
      "3   U0004      2022-04-17                  2               -1.040369   \n",
      "4   U0005      2022-03-13                  2               -0.971899   \n",
      "\n",
      "   Courses Enrolled  Login Frequency (per month)  \\\n",
      "0          1.531276                    -0.770452   \n",
      "1         -1.560650                     0.698708   \n",
      "2          0.758295                     1.310858   \n",
      "3          0.758295                     0.576278   \n",
      "4         -0.401177                    -1.015312   \n",
      "\n",
      "   Time Spent per Session (mins) Last Active Date  Forum Participation  \\\n",
      "0                       1.765516       2023-04-04            -0.790448   \n",
      "1                       0.317900       2023-11-22            -0.931235   \n",
      "2                       1.122470       2023-09-15             0.124667   \n",
      "3                      -0.578099       2022-11-22             0.476634   \n",
      "4                      -0.651242       2022-03-21             1.180569   \n",
      "\n",
      "   Quiz Participation Rate  ...  Feedback Sentiment  Support Ticket Sentiment  \\\n",
      "0                 1.487668  ...                   2                         3   \n",
      "1                 1.275840  ...                   2                         0   \n",
      "2                 0.677059  ...                   1                         2   \n",
      "3                -1.528260  ...                   2                         2   \n",
      "4                 1.025211  ...                   2                         2   \n",
      "\n",
      "   Incomplete Courses Count  Engagement_inper     churn  \\\n",
      "0                 -0.024652         -0.917253  1.523896   \n",
      "1                  0.679683          0.116365 -0.656213   \n",
      "2                 -0.728986         -1.367113 -0.656213   \n",
      "3                 -0.024652         -0.188324 -0.656213   \n",
      "4                  0.679683          0.308332 -0.656213   \n",
      "\n",
      "   Course Reminder Response  Gamified Progress Engagement  \\\n",
      "0                         1                             0   \n",
      "1                         1                             0   \n",
      "2                         1                             0   \n",
      "3                         0                             1   \n",
      "4                         0                             1   \n",
      "\n",
      "   AI Recommendation Click Rate  Engagement Score  Days Since Last Active  \n",
      "0                      0.840177            1075.5                     669  \n",
      "1                      0.430840            1512.0                     437  \n",
      "2                     -0.292336            2558.4                     505  \n",
      "3                      1.394363             852.0                     802  \n",
      "4                      0.502909             281.4                    1048  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Index(['User ID', 'Enrollment Date', 'Subscription Plan',\n",
      "       'Course Completion Rate', 'Courses Enrolled',\n",
      "       'Login Frequency (per month)', 'Time Spent per Session (mins)',\n",
      "       'Last Active Date', 'Forum Participation', 'Quiz Participation Rate',\n",
      "       'Assignment Submission Rate', 'Video Watch Completion Rate',\n",
      "       'Survey Response (1-5)', 'Feedback Sentiment',\n",
      "       'Support Ticket Sentiment', 'Incomplete Courses Count',\n",
      "       'Engagement_inper', 'churn', 'Course Reminder Response',\n",
      "       'Gamified Progress Engagement', 'AI Recommendation Click Rate',\n",
      "       'Engagement Score', 'Days Since Last Active'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Shape:\", df.shape)  # Should not be (0, N)\n",
    "print(df.head())  # Display first few rows\n",
    "print(df.columns)  # Ensure correct column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (1000, 23)\n",
      "Unique label values before processing: [3 0 2 1]\n",
      "Dataset shape after cleaning: (1000, 4)\n",
      "Unique label values after processing: [3 0 2 1]\n",
      "label\n",
      "1    0.430\n",
      "2    0.424\n",
      "0    0.145\n",
      "3    0.001\n",
      "Name: proportion, dtype: float64\n",
      "Number of training samples: 1204\n",
      "Number of testing samples: 516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Smruti Deshpande\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='95' max='95' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [95/95 44:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.370700</td>\n",
       "      <td>1.031580</td>\n",
       "      <td>0.705426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.212100</td>\n",
       "      <td>0.913807</td>\n",
       "      <td>0.759690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.009200</td>\n",
       "      <td>0.682088</td>\n",
       "      <td>0.744186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.826100</td>\n",
       "      <td>0.504846</td>\n",
       "      <td>0.891473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.459946</td>\n",
       "      <td>0.875969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 01:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8915\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check the shape of the initial dataset\n",
    "print(\"Original dataset shape:\", df.shape)\n",
    "\n",
    "# Ensure NA values in 'Support Ticket Sentiment' are replaced with 'neutral'\n",
    "sentiment_data = df[['Feedback Sentiment', 'Support Ticket Sentiment']].copy()\n",
    "sentiment_data['Support Ticket Sentiment'] = sentiment_data['Support Ticket Sentiment'].fillna('neutral')\n",
    "\n",
    "# Check unique label values to ensure proper mapping\n",
    "print(\"Unique label values before processing:\", sentiment_data['Support Ticket Sentiment'].unique())\n",
    "\n",
    "# Combine relevant features for sentiment analysis\n",
    "sentiment_data['text'] = sentiment_data['Feedback Sentiment'].astype(str) + \" \" + sentiment_data['Support Ticket Sentiment'].astype(str)\n",
    "\n",
    "# Directly use numeric labels (assuming they're already in 0, 1, 2, 3 format)\n",
    "sentiment_data['label'] = sentiment_data['Support Ticket Sentiment']\n",
    "\n",
    "# Ensure no NaN values in the dataset\n",
    "sentiment_data = sentiment_data.dropna(subset=['label'])\n",
    "\n",
    "# Convert labels to integers if needed\n",
    "sentiment_data['label'] = sentiment_data['label'].astype(int)\n",
    "\n",
    "# Check the dataset after cleaning\n",
    "print(\"Dataset shape after cleaning:\", sentiment_data.shape)\n",
    "print(\"Unique label values after processing:\", sentiment_data['label'].unique())\n",
    "\n",
    "# Check for class imbalance\n",
    "print(sentiment_data['label'].value_counts(normalize=True))\n",
    "\n",
    "# Apply Random Oversampling if there is class imbalance\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(sentiment_data[['text']], sentiment_data['label'])\n",
    "\n",
    "# Ensure there's data left for splitting\n",
    "if len(X_resampled) == 0:\n",
    "    print(\"The dataset is empty after resampling. Exiting process.\")\n",
    "    exit()\n",
    "\n",
    "# Increase test set size to ensure diverse validation set\n",
    "X_sentiment_train, X_sentiment_test, y_sentiment_train, y_sentiment_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.3, random_state=42  # Increased test size\n",
    ")\n",
    "\n",
    "# Verify the number of samples in each split\n",
    "print(\"Number of training samples:\", len(X_sentiment_train))\n",
    "print(\"Number of testing samples:\", len(X_sentiment_test))\n",
    "\n",
    "# Tokenization using BERT\n",
    "# Tokenization using BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Encode text data with truncation and padding\n",
    "train_encodings = tokenizer.batch_encode_plus(\n",
    "    X_sentiment_train['text'].tolist(),  # Use .tolist() on the 'text' column\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=128,  # Ensure appropriate input length\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer.batch_encode_plus(\n",
    "    X_sentiment_test['text'].tolist(),  # Use .tolist() on the 'text' column\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "\n",
    "# Convert the data into PyTorch datasets\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = SentimentDataset(train_encodings, y_sentiment_train)\n",
    "test_dataset = SentimentDataset(test_encodings, y_sentiment_test)\n",
    "\n",
    "# Use BERT with increased dropout regularization\n",
    "config = BertConfig.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=4,\n",
    "    hidden_dropout_prob=0.3,  # Increased dropout to reduce overfitting\n",
    "    attention_probs_dropout_prob=0.3\n",
    ")\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)\n",
    "\n",
    "# Training Arguments with Early Stopping and Learning Rate Scheduler\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,  # Reduce epochs to prevent overfitting\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate after every epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=32,  # Increased batch size for better stability\n",
    "    per_device_eval_batch_size=64,\n",
    "    gradient_accumulation_steps=2,  # Simulate larger batch sizes\n",
    "    warmup_steps=0,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,  # Reduced learning rate\n",
    "    lr_scheduler_type=\"linear\",  # Gradually reduce learning rate\n",
    "    load_best_model_at_end=True,  # Load best model based on validation loss\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=2,  # Keep only the best 2 models\n",
    ")\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStoppingCallback(early_stopping_patience=3)  # Stop if no improvement in 3 eval steps\n",
    "\n",
    "# Custom compute_metrics function\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = torch.tensor(predictions)  # Convert predictions to a tensor\n",
    "    predictions = torch.argmax(predictions, dim=-1)  # Convert logits to predicted class\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {'accuracy': accuracy}\n",
    "\n",
    "\n",
    "# Trainer with early stopping\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,  # Pass the custom metric function\n",
    "    callbacks=[early_stopping]  # Add early stopping\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_result = trainer.evaluate()\n",
    "print(f\"Accuracy: {eval_result['eval_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('./results')\n",
    "tokenizer = joblib.load('./results/tokenizer.joblib')\n",
    "\n",
    "# Test data\n",
    "test_texts = [\"The product was great, I had an amazing experience!\", \"The service was terrible, I am very disappointed.\"]\n",
    "test_labels = [1, 0]  # Example test labels\n",
    "\n",
    "# Tokenize the test data\n",
    "test_encodings = tokenizer.batch_encode_plus(\n",
    "    test_texts,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Create a PyTorch dataset for evaluation\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = SentimentDataset(test_encodings, test_labels)\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate(model, test_dataset):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for batch in torch.utils.data.DataLoader(test_dataset, batch_size=32):\n",
    "        inputs = {key: val.to(model.device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(model.device)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "evaluate(model, test_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
